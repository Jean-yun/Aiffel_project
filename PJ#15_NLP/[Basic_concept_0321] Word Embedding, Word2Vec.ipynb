{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac6f695c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p ~/aiffel/word_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a63bd4bd",
   "metadata": {},
   "source": [
    "# 1. 원핫 인코딩으로 벡터화\n",
    "- 모든 단어의 관계를 독립적으로 정의하는 원-핫 인코딩이라는 방식도 있습니다. \n",
    "- 원-핫 인코딩을 하기 위해서는 우선 갖고 있는 텍스트 데이터에서 단어들의 집합인 단어장(vocabulary) 을 만듭니다. 그 후 단어장에 있는 모든 단어에 대해서 1부터 V까지 고유한 정수를 부여합니다. \n",
    "- 이 정수는 단어장에 있는 각 단어의 일종의 인덱스 역할을 합니다. \n",
    "- 각 단어는 V차원의 벡터로 표현되는데, 해당 단어의 인덱스 위치만 1이고 나머지는 전부 0의 값을 가지는 벡터가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4cf841",
   "metadata": {},
   "source": [
    "## 1) 패키지 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71c5b392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /opt/conda/lib/python3.9/site-packages (0.5.2)\n",
      "Requirement already satisfied: tweepy>=3.7.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (3.10.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.9/site-packages (from konlpy) (0.4.4)\n",
      "Requirement already satisfied: beautifulsoup4==4.6.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (4.6.0)\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.6 in /opt/conda/lib/python3.9/site-packages (from konlpy) (1.22.2)\n",
      "Requirement already satisfied: lxml>=4.1.0 in /opt/conda/lib/python3.9/site-packages (from konlpy) (4.6.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.16.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (2.26.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from tweepy>=3.7.0->konlpy) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.2.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.26.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.0.12)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.9/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b7ab10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from konlpy.tag import Okt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "570ba841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'임금님 귀는 당나귀 귀! 임금님 귀는 당나귀 귀! 실컷~ 소리치고 나니 속이 확 뚫려 살 것 같았어.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"임금님 귀는 당나귀 귀! 임금님 귀는 당나귀 귀! 실컷~ 소리치고 나니 속이 확 뚫려 살 것 같았어.\"\n",
    "text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32349c56",
   "metadata": {},
   "source": [
    "## 2) 전처리\n",
    "- 정규 표현식을 사용하여 특수문자들을 제거하고자 합니다.\n",
    "-  일반적으로 자음의 범위는 'ㄱ ~ ㅎ', 모음의 범위는 'ㅏ ~ ㅣ'와 같이 지정할 수 있습니다.\n",
    "- 한글, 공백을 제외한 모든 문자를 표현하는 regex : [^ㄱ-ㅎㅏ-ㅣ가-힣 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d88dc6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임금님 귀는 당나귀 귀 임금님 귀는 당나귀 귀 실컷 소리치고 나니 속이 확 뚫려 살 것 같았어\n"
     ]
    }
   ],
   "source": [
    "#reg (한글이 아닌 것) 모두를 공백으로 교체한다\n",
    "\n",
    "reg = re.compile(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\")\n",
    "text = reg.sub('', text)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c42c9a",
   "metadata": {},
   "source": [
    "## 3) 토큰화\n",
    "-  KoNLPy에 내장된 Okt 형태소 분석기를 사용해서 토큰 단위를 나눠준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03154721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['임금님', '귀', '는', '당나귀', '귀', '임금님', '귀', '는', '당나귀', '귀', '실컷', '소리', '치고', '나니', '속이', '확', '뚫려', '살', '것', '같았어']\n"
     ]
    }
   ],
   "source": [
    "okt=Okt()\n",
    "tokens = okt.morphs(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f92c709",
   "metadata": {},
   "source": [
    "## 4) 단어장 만들기\n",
    "- 파이썬의 Counter 서브클래스를 사용해서 단어의 빈도를 카운트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7682289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'귀': 4, '임금님': 2, '는': 2, '당나귀': 2, '실컷': 1, '소리': 1, '치고': 1, '나니': 1, '속이': 1, '확': 1, '뚫려': 1, '살': 1, '것': 1, '같았어': 1})\n"
     ]
    }
   ],
   "source": [
    "vocab = Counter(tokens)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0480be86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['임금님']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2280f2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('귀', 4), ('임금님', 2), ('는', 2), ('당나귀', 2), ('실컷', 1)]\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 5\n",
    "vocab = vocab.most_common(vocab_size) # 등장 빈도수가 높은 상위 5개의 단어만 저장\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d25515c",
   "metadata": {},
   "source": [
    "-  most_common()는 상위 빈도수를 가진 단어를 주어진 수만큼 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ce1e0da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'귀': 1, '임금님': 2, '는': 3, '당나귀': 4, '실컷': 5}\n"
     ]
    }
   ],
   "source": [
    "word2idx={word[0] : index+1 for index, word in enumerate(vocab)}\n",
    "print(word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0f65fa",
   "metadata": {},
   "source": [
    "- 높은 빈도수를 가진 단어일수록 낮은 정수 인덱스를 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387ea787",
   "metadata": {},
   "source": [
    "## 5) 원-핫 벡터 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae924235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(word, word2index):\n",
    "       one_hot_vector = [0]*(len(word2index))\n",
    "       index = word2index[word]\n",
    "       one_hot_vector[index-1] = 1\n",
    "       return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "04e3a799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_encoding(\"임금님\", word2idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1009856a",
   "metadata": {},
   "source": [
    "### 케라스를 통한 원-핫 인코딩(one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13ef808e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "임포트 완료\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "print(\"임포트 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b699a736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['강아지', '고양이', '강아지'], ['애교', '고양이'], ['컴퓨터', '노트북']]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [['강아지', '고양이', '강아지'],['애교', '고양이'], ['컴퓨터', '노트북']]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1db8f5bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'강아지': 1, '고양이': 2, '애교': 3, '컴퓨터': 4, '노트북': 5}\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(text)\n",
    "print(t.word_index) # 각 단어에 대한 인코딩 결과 출력."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8fcc8ef",
   "metadata": {},
   "source": [
    "- 케라스 토크나이저를 사용하면 주어진 텍스트로부터 단어장을 만들고, 단어장의 각 단어에 고유한 정수를 맵핑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "940a1644",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(t.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4322df5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 2, 1, 4]]\n"
     ]
    }
   ],
   "source": [
    "sub_text = ['강아지', '고양이', '강아지', '컴퓨터']\n",
    "encoded = t.texts_to_sequences([sub_text])\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e806fc1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 1. 0. 0. 0.]\n",
      "  [0. 1. 0. 0. 0. 0.]\n",
      "  [0. 0. 0. 0. 1. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "one_hot = to_categorical(encoded, num_classes = vocab_size)\n",
    "print(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dcc075b",
   "metadata": {},
   "source": [
    "# 2. Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b8b2474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.9/site-packages (3.6.5)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.9/site-packages (from nltk) (2022.3.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk) (8.0.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.9/site-packages (from nltk) (4.62.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: gensim in /opt/conda/lib/python3.9/site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.22.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.9/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.9/site-packages (from gensim) (1.7.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nltk\n",
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc430e0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package abc to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/abc.zip.\n",
      "[nltk_data] Downloading package punkt to /aiffel/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('abc')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fb0afc25",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import abc\n",
    "corpus = abc.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "912117c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PM', 'denies', 'knowledge', 'of', 'AWB', 'kickbacks', 'The', 'Prime', 'Minister', 'has', 'denied', 'he', 'knew', 'AWB', 'was', 'paying', 'kickbacks', 'to', 'Iraq', 'despite', 'writing', 'to', 'the', 'wheat', 'exporter', 'asking', 'to', 'be', 'kept', 'fully', 'informed', 'on', 'Iraq', 'wheat', 'sales', '.'], ['Letters', 'from', 'John', 'Howard', 'and', 'Deputy', 'Prime', 'Minister', 'Mark', 'Vaile', 'to', 'AWB', 'have', 'been', 'released', 'by', 'the', 'Cole', 'inquiry', 'into', 'the', 'oil', 'for', 'food', 'program', '.'], ['In', 'one', 'of', 'the', 'letters', 'Mr', 'Howard', 'asks', 'AWB', 'managing', 'director', 'Andrew', 'Lindberg', 'to', 'remain', 'in', 'close', 'contact', 'with', 'the', 'Government', 'on', 'Iraq', 'wheat', 'sales', '.']]\n"
     ]
    }
   ],
   "source": [
    "print(corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1526340e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "코퍼스의 크기 : 29059\n"
     ]
    }
   ],
   "source": [
    "print('코퍼스의 크기 :',len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd726f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = Word2Vec(sentences = corpus, vector_size = 100, window = 5, min_count = 5, workers = 4, sg = 0)\n",
    "print(\"모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9a73c7",
   "metadata": {},
   "source": [
    "- 이 corpus를 가지고 Word2Vec 훈련시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af30e74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9233802556991577), ('skull', 0.9107487797737122), ('Bang', 0.9055431485176086), ('asteroid', 0.9051916003227234), ('third', 0.9019238352775574), ('baby', 0.8993036150932312), ('dog', 0.8985596299171448), ('bought', 0.8974378108978271), ('rally', 0.8911734819412231), ('dinosaur', 0.8890715837478638)]\n"
     ]
    }
   ],
   "source": [
    "model_result = model.wv.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39d0c43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델  load 완료!\n"
     ]
    }
   ],
   "source": [
    "# 모델 저장하고 로드하는 방법\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model.wv.save_word2vec_format('~/aiffel/word_embedding/w2v') \n",
    "loaded_model = KeyedVectors.load_word2vec_format(\"~/aiffel/word_embedding/w2v\")\n",
    "print(\"모델  load 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2c846b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('woman', 0.9233802556991577), ('skull', 0.9107487797737122), ('Bang', 0.9055431485176086), ('asteroid', 0.9051916003227234), ('third', 0.9019238352775574), ('baby', 0.8993036150932312), ('dog', 0.8985596299171448), ('bought', 0.8974378108978271), ('rally', 0.8911734819412231), ('dinosaur', 0.8890715837478638)]\n"
     ]
    }
   ],
   "source": [
    "model_result = loaded_model.most_similar(\"man\")\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0400da29",
   "metadata": {},
   "source": [
    "# 3. FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf39ef17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FastText 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "fasttext_model = FastText(corpus, window=5, min_count=5, workers=4, sg=1)\n",
    "print(\"FastText 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "996c40a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('extracting', 0.93874591588974),\n",
       " ('lifting', 0.9318686723709106),\n",
       " ('malting', 0.931620717048645),\n",
       " ('mounting', 0.9306465983390808),\n",
       " ('shooting', 0.9303444623947144),\n",
       " ('fluctuating', 0.929731547832489),\n",
       " ('melting', 0.9294134378433228),\n",
       " ('reflecting', 0.9282941222190857),\n",
       " ('resolving', 0.9276877045631409),\n",
       " ('attracting', 0.9265851974487305)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('overacting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8cae1165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('memory', 0.94884192943573),\n",
       " ('mechanisms', 0.8743845820426941),\n",
       " ('mechanism', 0.8734592199325562),\n",
       " ('musical', 0.8589513897895813),\n",
       " ('basic', 0.8587403893470764),\n",
       " ('technical', 0.8539524078369141),\n",
       " ('intelligence', 0.8514528870582581),\n",
       " ('imagine', 0.8460912108421326),\n",
       " ('mechanical', 0.8449276089668274),\n",
       " ('perform', 0.8426198363304138)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fasttext_model.wv.most_similar('memoryy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c423d",
   "metadata": {},
   "source": [
    "- 단어장에 없지만 가장 유사한 단어 10개를 출력해준다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9619399a",
   "metadata": {},
   "source": [
    "# 4. GloVe\n",
    "- 글로브(Global Vectors for Word Representation, GloVe) 는 2014년에 미국 스탠포드 대학에서 개발한 워드 임베딩 방법론입니다. \n",
    "- 워드 임베딩의 두 가지 접근 방법인 카운트 기반과 예측 기반 두 가지 방법을 모두 사용했다 는 것이 특징입니다.\n",
    "- 다만, GloVe는 2014년에 개발되었고, 2015년에 1.2 버전이 나온 이후로는 관리되지 않고 있기 때문에 최신 버전의 python에서는 GloVe를 설치하는 것이 불가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6712a6eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat', 0.9218004941940308),\n",
       " ('dogs', 0.8513158559799194),\n",
       " ('horse', 0.7907583713531494),\n",
       " ('puppy', 0.7754920721054077),\n",
       " ('pet', 0.7724708318710327),\n",
       " ('rabbit', 0.7720814347267151),\n",
       " ('pig', 0.7490062117576599),\n",
       " ('snake', 0.7399188876152039),\n",
       " ('baby', 0.7395570278167725),\n",
       " ('bite', 0.7387937307357788)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "glove_model = api.load(\"glove-wiki-gigaword-50\")  # glove vectors 다운로드\n",
    "glove_model.most_similar(\"dog\")  # 'dog'과 비슷한 단어 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "036bed02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('impudence', 0.7842012047767639),\n",
       " ('puerile', 0.7816032767295837),\n",
       " ('winningly', 0.7644237875938416),\n",
       " ('grossness', 0.7576098442077637),\n",
       " ('deconstructions', 0.748936653137207),\n",
       " ('over-the-top', 0.7460805773735046),\n",
       " ('buffoonery', 0.746045708656311),\n",
       " ('impetuosity', 0.7415392398834229),\n",
       " ('sophomoric', 0.736961841583252),\n",
       " ('zaniness', 0.7353197336196899)]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_model.most_similar('overacting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45747940",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'memoryy' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32/4082020240.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mglove_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'memoryy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                 \u001b[0mmean\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    775\u001b[0m                     \u001b[0mall_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \"\"\"\n\u001b[0;32m--> 438\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfill_norms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'memoryy' not present\""
     ]
    }
   ],
   "source": [
    "glove_model.most_similar('memoryy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b84bbb53",
   "metadata": {},
   "source": [
    "- GloVe는 Word2Vec과 같이 OOV 문제를 가지고 있어서 'memoryy'라는 단어는 인식하지 못합니다. 또한 pre-trained GloVe 모델은 한글이나 알파벳 대문자가 포함된 데이터셋으로 학습하지 않았기 때문에 알파벳 소문자만 인식한다는 사실에 유의하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5be78a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
